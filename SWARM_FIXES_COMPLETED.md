# Ralph Swarm - Comprehensive Fix Guide

**Date**: 2026-01-24  
**Analysis By**: Deep code review + agent swarm best practices research  
**Priority**: CRITICAL - Fix before production use

NOTE: This file is a scratchpad from a prior analysis and is not part of
`RALPH_IMPROVEMENTS.md` remaining-work list.

---

## Executive Summary

The ralph-live swarm system has a solid architectural foundation following industry best practices (Anthropic's "Building Effective Agents", OpenAI Swarm patterns). However, there are **5 critical bugs** that will cause data loss and work duplication, plus **6 dead functions** cluttering the codebase.

**Risk Level**: üî¥ HIGH - Resume operations can corrupt state and lose completed work

**Estimated Fix Time**: 4-6 hours for critical issues, 2 hours for cleanup

---

## Table of Contents

1. [Critical Fixes](#critical-fixes)
2. [Moderate Fixes](#moderate-fixes)
3. [Code Cleanup](#code-cleanup)
4. [Performance Optimizations](#performance-optimizations)
5. [Testing Requirements](#testing-requirements)
6. [Best Practices Enhancements](#best-practices-enhancements)

---

## Critical Fixes

### üî¥ CRITICAL #1: Resume Corrupts State and Loses Work

**Files**: `ralph-refactor/lib/swarm_db.sh:991-1028`, `ralph-refactor/ralph-swarm:286-319`

**Problem**: When resuming a swarm run after crash:
- Resets `started_at` to current time ‚Üí breaks timeout calculations (scheduler uses this for elapsed time)
- Blindly resets ALL `in_progress` tasks to `pending` ‚Üí even if they're already in `completed_tasks` table
- Doesn't verify against `completed_tasks` table (the source of truth)
- Can cause same task to run 2-3 times if you resume multiple times

**Impact**: 
- Tasks are re-done unnecessarily (wasted tokens/time)
- Completed work can be lost if worker re-writes files
- Timeout calculations are wrong (thinks run just started)

**Fix for `ralph-refactor/lib/swarm_db.sh`**:

Replace lines 991-1028 with:

```bash
swarm_db_resume_run() {
    local db_path="$RALPH_DIR/swarm.db"
    local run_id="$1"

    # Check if run exists
    local status
    status=$(sqlite3 "$db_path" "SELECT status FROM swarm_runs WHERE run_id = '$run_id';")

    if [ -z "$status" ]; then
        echo "Run not found: $run_id"
        return 1
    fi

    if [ "$status" = "completed" ]; then
        echo "Run already completed: $run_id"
        return 1
    fi

    # Check for pending or in_progress tasks
    local resumable_tasks
    resumable_tasks=$(sqlite3 "$db_path" "SELECT COUNT(*) FROM tasks WHERE run_id = '$run_id' AND status IN ('pending', 'in_progress');")

    if [ "$resumable_tasks" -eq 0 ]; then
        echo "Run has no remaining tasks: $run_id"
        return 1
    fi

    # Resume the run - CRITICAL: Don't reset started_at!
    sqlite3 "$db_path" <<EOF
BEGIN TRANSACTION;

-- Reset workers (they're all dead after crash)
UPDATE workers 
SET status = 'stopped', 
    current_task_id = NULL, 
    last_heartbeat = NULL
WHERE run_id = '$run_id';

-- Release all locks from dead workers
DELETE FROM file_locks WHERE run_id = '$run_id';

-- Reset in_progress tasks ONLY if not already in completed_tasks
-- Use task_hash to check if work is actually done
UPDATE tasks 
SET status = 'pending', 
    worker_id = NULL, 
    started_at = NULL,
    stall_count = COALESCE(stall_count, 0) + 1
WHERE run_id = '$run_id' 
  AND status = 'in_progress'
  AND task_hash NOT IN (
    SELECT task_hash FROM completed_tasks WHERE task_hash IS NOT NULL
  );

-- Mark tasks as completed if they're in completed_tasks but status is wrong
-- This handles the case where DB update failed but task was actually done
UPDATE tasks t
SET status = 'completed',
    completed_at = (
      SELECT completed_at FROM completed_tasks ct 
      WHERE ct.task_hash = t.task_hash 
      LIMIT 1
    )
WHERE run_id = '$run_id'
  AND status = 'in_progress'
  AND task_hash IN (
    SELECT task_hash FROM completed_tasks WHERE task_hash IS NOT NULL
  );

-- Mark run as running again - KEEP ORIGINAL started_at for timeout calculations!
UPDATE swarm_runs 
SET status = 'running', 
    completed_at = NULL 
WHERE run_id = '$run_id';

COMMIT;
EOF

    echo "$run_id"
}
```

**Fix for `ralph-refactor/ralph-swarm`**:

Replace lines 300-306 with:

```bash
# Resume the run using the FIXED swarm_db_resume_run function
if ! swarm_db_resume_run "$run_id_result"; then
    echo "Failed to resume run: $run_id_result"
    rm -f "$task_list_file"
    return 1
fi

echo "Run ID: $run_id_result"
```

**Remove these lines** (287-306 in current code):
- The manual SQL that resets started_at
- The workers/tasks update that doesn't check completed_tasks

**Test**:
```bash
# Start a swarm, let it complete 2 tasks, then kill workers
./ralph-swarm --devplan test.md --workers 2 &
sleep 30
pkill -9 -f swarm_worker

# Resume - should NOT re-run the 2 completed tasks
./ralph-swarm --resume <RUN_ID>

# Verify in DB
sqlite3 ~/.ralph/swarm.db "SELECT task_text, status, stall_count FROM tasks WHERE run_id='<RUN_ID>';"
# stall_count should be 0 for completed tasks (not re-run)
```

---

### üî¥ CRITICAL #2: Race Condition in Task Claiming

**File**: `ralph-refactor/lib/swarm_db.sh:327-384`

**Problem**: 
- Two workers can claim the same task simultaneously
- The `BEGIN IMMEDIATE TRANSACTION` + retry loop helps but doesn't fully prevent it
- No verification after claiming that worker actually got the task
- No database constraint preventing double-claims

**Impact**:
- Same task runs twice (wasted resources)
- Two workers modify same files ‚Üí merge conflicts
- Database inconsistency (task assigned to multiple workers)

**Fix**:

1. **Add to `swarm_db_init()` schema** (line 109 in swarm_db.sh, after creating tasks table):

```sql
-- Prevent multiple workers from claiming same task
CREATE UNIQUE INDEX IF NOT EXISTS idx_task_in_progress 
  ON tasks(id) 
  WHERE status = 'in_progress';
```

2. **Replace `swarm_db_claim_task()` lines 327-384** with:

```bash
swarm_db_claim_task() {
    local db_path="$RALPH_DIR/swarm.db"
    local worker_id="$1"

    local task_id
    local task_text
    local estimated_files
    local devplan_line

    local max_retries=20
    local retry_delay=0.1
    local retry_count=0

    while [ $retry_count -lt $max_retries ]; do
        task_id=$(sqlite3 "$db_path" <<EOF 2>/dev/null
BEGIN IMMEDIATE TRANSACTION;

UPDATE tasks
SET status = 'in_progress',
    worker_id = $worker_id,
    started_at = datetime('now')
WHERE id IN (
    SELECT id FROM tasks
    WHERE run_id = (SELECT run_id FROM workers WHERE id = $worker_id)
    AND status = 'pending'
    ORDER BY priority ASC, id ASC
    LIMIT 1
)
RETURNING id;

COMMIT;
EOF
)

        local exit_code=$?
        
        # If claim succeeded, verify we actually got the task
        if [ $exit_code -eq 0 ] && [ -n "$task_id" ]; then
            # VERIFICATION: Check that WE are the worker assigned to this task
            local assigned_worker
            assigned_worker=$(sqlite3 "$db_path" "SELECT worker_id FROM tasks WHERE id = $task_id AND status = 'in_progress';")
            
            if [ "$assigned_worker" = "$worker_id" ]; then
                # Success! We own this task
                break
            else
                # Race condition: another worker grabbed it between our update and verify
                echo "[RACE] Worker $worker_id lost race for task $task_id to worker $assigned_worker" >&2
                task_id=""
            fi
        fi

        retry_count=$((retry_count + 1))
        if [ $retry_count -lt $max_retries ]; then
            sleep $retry_delay
            retry_delay=$(awk "BEGIN {print $retry_delay * 1.5}")  # Exponential backoff
        fi
    done

    if [ -z "$task_id" ]; then
        # No pending tasks available after retries
        echo ""
        return 0
    fi

    # Fetch task details
    task_text=$(sqlite3 "$db_path" "SELECT task_text FROM tasks WHERE id = $task_id")
    estimated_files=$(sqlite3 "$db_path" "SELECT estimated_files FROM tasks WHERE id = $task_id")
    devplan_line=$(sqlite3 "$db_path" "SELECT devplan_line FROM tasks WHERE id = $task_id")

    echo "$task_id|$task_text|$estimated_files|$devplan_line"
}
```

**Test**:
```bash
# Start swarm with 4 workers on small devplan (10 tasks)
./ralph-swarm --devplan test.md --workers 4

# Check for duplicate task assignments
sqlite3 ~/.ralph/swarm.db "
  SELECT task_id, COUNT(*) as worker_count 
  FROM tasks 
  WHERE status = 'in_progress' 
  GROUP BY task_id 
  HAVING worker_count > 1;
"
# Should return ZERO rows (no duplicates)
```

---

### üî¥ CRITICAL #3: File Locking System Is Completely Unwired

**File**: `ralph-refactor/lib/swarm_worker.sh:364-530`

**Problem**:
- Database has `file_locks` table
- Functions exist: `swarm_db_acquire_locks`, `swarm_db_release_locks`
- But `swarm_worker_execute_task` NEVER calls them!
- Result: Multiple workers can edit same file simultaneously ‚Üí merge conflicts

**Impact**:
- Git merge conflicts when combining worker branches
- Lost work when one worker overwrites another's changes
- Artifact extraction failures

**Fix for `swarm_worker_execute_task()`**:

Replace lines 364-530 with this enhanced version:

```bash
swarm_worker_execute_task() {
    local run_id="$1"
    local worker_num="$2"
    local task_id="$3"
    local task_text="$4"
    local estimated_files="$5"
    local devplan_line="$6"
    local devplan_path="$7"
    local ralph_path="$8"
    local log_file="$9"

    local worker_dir="$RALPH_DIR/swarm/runs/$run_id/worker-$worker_num"
    local repo_dir="$worker_dir/repo"

    if [ ! -d "$repo_dir" ]; then
        echo "[$(date)] Error: worker repo dir missing: $repo_dir" 1>&2
        return 1
    fi

    # Get worker_id for locking
    local worker_id
    worker_id=$(sqlite3 "$RALPH_DIR/swarm.db" "SELECT id FROM workers WHERE run_id = '$run_id' AND worker_num = $worker_num ORDER BY id DESC LIMIT 1;")

    # ACQUIRE FILE LOCKS BEFORE EXECUTION
    if [ -n "$estimated_files" ] && [ "$estimated_files" != "[]" ] && [ "$estimated_files" != "null" ]; then
        echo "[$(date)] Acquiring locks for estimated files: $estimated_files"
        
        if ! swarm_db_acquire_locks "$run_id" "$worker_id" "$task_id" "$estimated_files" 2>/dev/null; then
            echo "[$(date)] Failed to acquire file locks for task $task_id" 1>&2
            
            # Check if locks are held by another worker
            local locked_by
            locked_by=$(swarm_db_check_conflicts "$run_id" "$estimated_files" 2>/dev/null)
            
            if [ -n "$locked_by" ]; then
                echo "[$(date)] Files locked by: $locked_by" 1>&2
                echo "[$(date)] Re-queuing task $task_id for later attempt" 1>&2
                
                # Re-queue task (don't fail it, just defer)
                sqlite3 "$RALPH_DIR/swarm.db" <<EOF
UPDATE tasks 
SET status = 'pending', 
    worker_id = NULL, 
    started_at = NULL,
    stall_count = COALESCE(stall_count, 0) + 1
WHERE id = $task_id;
EOF
                return 1
            fi
        fi
        
        echo "[$(date)] Locks acquired for task $task_id"
    fi

    # Ensure json_extract_text is available for completion detection
    if ! command -v json_extract_text >/dev/null 2>&1; then
        # shellcheck source=ralph-refactor/lib/json.sh
        source "$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/json.sh"
    fi

    local prompt
    prompt=$(cat <<EOF
CRITICAL INSTRUCTION: You MUST end your response with the exact string "<promise>COMPLETE</promise>" when you have finished the task. Do not omit this marker under any circumstances.

You are a swarm worker (#$worker_num) operating inside a git worktree for a NEW PROJECT.

Task ($task_id): $task_text

Constraints:
- Make changes ONLY in this repository (current working directory).
- This is a fresh project - create the necessary files and structure for the task.
- DO NOT reference, copy, or include any files from ralph-refactor/, ralph-tui/, swarm-dashboard/, or opencode-ralph* directories - these are internal tooling files and must NOT be included in the project.
- Run relevant tests/linters if they exist.
- Create a git commit for your changes with a clear message.
- When finished, you MUST output exactly: <promise>COMPLETE</promise>

Remember: End your response with "<promise>COMPLETE</promise>" to signal task completion. This is required for the swarm system to recognize your work as done.

If you need context, inspect files in the repo. Focus on building the requested functionality from scratch.
EOF
)

    echo "[$(date)] Running OpenCode for task $task_id"

    if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
        echo -e "${YELLOW}‚ñ∏${NC} Worker $worker_num executing task $task_id..."
        echo -e "${YELLOW}‚ñ∏${NC}   ${task_text:0:100}"
        echo ""
    fi

    local opencode_cmd="opencode run"
    local full_model=""

    # Construct model argument in "provider/model" format if needed
    if [ -n "${RALPH_LLM_MODEL:-}" ]; then
        if [[ "${RALPH_LLM_MODEL}" == *"/"* ]]; then
            full_model="${RALPH_LLM_MODEL}"
        elif [ -n "${RALPH_LLM_PROVIDER:-}" ]; then
            full_model="${RALPH_LLM_PROVIDER}/${RALPH_LLM_MODEL}"
        else
            full_model="${RALPH_LLM_MODEL}"
        fi
    fi

    if [ -n "$full_model" ]; then
        opencode_cmd="$opencode_cmd --model $full_model"
    fi

    local timeout_seconds="${SWARM_TASK_TIMEOUT:-600}"
    local json_output
    local execution_failed=false

    if ! json_output=$(cd "$repo_dir" && timeout "$timeout_seconds" $opencode_cmd --format json "$prompt" 2>&1); then
        execution_failed=true
        local exit_code=$?
        
        # ALWAYS release locks on failure
        swarm_db_release_locks "$worker_id" 2>/dev/null || true
        
        if [ $exit_code -eq 124 ]; then
            echo "[$(date)] Task execution failed (timeout after ${timeout_seconds}s)" 1>&2
            if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
                echo -e "${RED}‚úó${NC} Worker $worker_num task $task_id failed: timeout after ${timeout_seconds}s"
            fi
        else
            echo "[$(date)] Task execution failed (opencode error)" 1>&2
            echo "$json_output" | head -c 300 1>&2
            if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
                echo -e "${RED}‚úó${NC} Worker $worker_num task $task_id failed: opencode error"
                echo -e "${RED}‚úó${NC}   $(echo "$json_output" | head -c 150)..."
            fi
        fi
        return 1
    fi

    # Best-effort: record token/cost stats if possible
    local prompt_tokens=0
    local completion_tokens=0
    local cost=0
    if command -v jq >/dev/null 2>&1; then
        # Single jq call for efficiency
        local stats
        stats=$(echo "$json_output" | jq -s '{
            prompt: (map(select(.part.tokens.input)) | map(.part.tokens.input) | add // 0),
            completion: (map(select(.part.tokens.output)) | map(.part.tokens.output) | add // 0),
            cost: (map(select(.part.cost)) | map(.part.cost) | add // 0)
        }' 2>/dev/null) || stats='{"prompt":0,"completion":0,"cost":0}'
        
        prompt_tokens=$(echo "$stats" | jq -r '.prompt')
        completion_tokens=$(echo "$stats" | jq -r '.completion')
        cost=$(echo "$stats" | jq -r '.cost')
    fi
    
    if command -v swarm_db_record_task_cost >/dev/null 2>&1; then
        swarm_db_record_task_cost "$run_id" "$task_id" "$prompt_tokens" "$completion_tokens" "$cost" >/dev/null 2>&1 || true
    fi

    if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
        echo -e "${BLUE}‚úì${NC} API call complete: ${prompt_tokens}‚Üí${completion_tokens} tokens | \$${cost}"
        if [ "$completion_tokens" -eq 0 ]; then
            echo -e "${YELLOW}‚ö†${NC} Warning: 0 tokens returned. Full response saved to: ${repo_dir}/.swarm_debug_${task_id}.json"
            echo "$json_output" > "${repo_dir}/.swarm_debug_${task_id}.json"
        fi
        echo ""
    fi

    local text_output
    text_output=$(json_extract_text "$json_output" 2>/dev/null || true)

    # Debug: Warn if text extraction failed but tokens were generated
    if [ -z "$text_output" ] && [ "$completion_tokens" -gt 0 ]; then
        echo "[$(date)] DEBUG: Text extraction failed despite $completion_tokens completion tokens" 1>&2
        echo "[$(date)] DEBUG: Full JSON saved to: ${repo_dir}/.swarm_text_debug_${task_id}.json" 1>&2
        echo "$json_output" > "${repo_dir}/.swarm_text_debug_${task_id}.json"
    fi

    # Check for completion using multiple patterns
    local completed=false
    if echo "$text_output" | grep -qiE "<promise>COMPLETE</promise>|Task completed|task completed|completed successfully|All done|Task finished|Done|done"; then
        completed=true
    fi
    
    if $completed; then
        echo "[$(date)] Task execution successful"
        
        # RELEASE LOCKS AFTER SUCCESSFUL COMPLETION
        swarm_db_release_locks "$worker_id" 2>/dev/null || true
        echo "[$(date)] Locks released for task $task_id"
        
        if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
            echo -e "${GREEN}‚úì${NC} Worker $worker_num completed task $task_id"
            echo ""

            # Show tool call summary
            echo "$text_output" | tr '|' '\n' | grep -vE '^\[RALPH\]|^=== Task|^=================================|^[0-9]\+' | while IFS= read -r line; do
                line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                [ -z "$line" ] && continue

                if echo "$line" | grep -qE '^(Read|Write|Edit|Bash|grep|glob|task|webfetch|codesearch|websearch|todoread|todowrite)'; then
                    echo -e "  ${CYAN}‚Üí $line${NC}"
                elif echo "$line" | grep -qE '^(‚úÖ|‚ùå|‚ö†Ô∏è)'; then
                    echo -e "  ${GREEN}$line${NC}"
                fi
            done
            echo ""
        fi
        return 0
    fi

    # RELEASE LOCKS ON INCOMPLETE/FAILED TASK
    swarm_db_release_locks "$worker_id" 2>/dev/null || true
    
    echo "[$(date)] Task execution did not return completion promise" 1>&2
    if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
        echo -e "${YELLOW}‚ö†${NC} Worker $worker_num task $task_id did not complete (no promise)"
    fi
    return 1
}
```

**Key Changes**:
1. Get `worker_id` at start (needed for locking)
2. Acquire locks BEFORE running opencode
3. If locks fail, re-queue task (don't fail it permanently)
4. Release locks after completion OR failure
5. Improved token aggregation (single jq call)

**Test**:
```bash
# Create devplan with 2 tasks that touch same file
cat > test.md <<EOF
# Test Plan
1. Create src/main.py with hello function
2. Add world function to src/main.py
EOF

# Run with 2 workers
./ralph-swarm --devplan test.md --workers 2

# Check locks in DB during execution
watch -n 1 "sqlite3 ~/.ralph/swarm.db 'SELECT pattern, worker_id FROM file_locks;'"

# Should see locks appear and disappear as tasks run
# Should NEVER see same pattern locked by 2 workers simultaneously
```

---

### üî¥ CRITICAL #4: Artifact Merging Can Lose Work

**File**: `ralph-refactor/lib/swarm_artifacts.sh:562-567`

**Problem**:
- Silently skips files matching `ralph-refactor/*`, `opencode-ralph*/*` patterns
- But what if task LEGITIMATELY created `opencode-ralph-plugin/` for the project?
- No way to distinguish internal tooling from project files
- Multiple workers editing same file: last one wins (no conflict detection)

**Impact**:
- Legitimate project files are lost
- Merge conflicts go undetected
- No verification that all completed tasks have their changes merged

**Fix for `swarm_extract_merged_artifacts()`**:

Replace lines 558-578 with:

```bash
if [ -n "$changed_files" ]; then
    while IFS= read -r file; do
        if [ -n "$file" ]; then
            # Skip ONLY if file is in .gitignore or is clearly internal
            local should_skip=false
            
            # Check if file path starts with known internal directories AT ROOT LEVEL
            case "$file" in
                ralph-refactor/*|ralph-tui/*|swarm-dashboard/*|.git/*|*.db)
                    # Only skip if this is a ROOT-level internal directory
                    if [ ! -f "$repo_dir/.ralph_project_marker" ]; then
                        # This is ralphussy itself, skip these
                        should_skip=true
                    fi
                    ;;
                opencode-ralph/*|opencode-ralph-slash/*)
                    # Only skip opencode-ralph if it's the main repo's copy
                    # Allow project-specific opencode plugins
                    local file_path="$repo_dir/$file"
                    if [ -L "$file_path" ] || grep -q "opencode-ralph" "$repo_dir/.gitmodules" 2>/dev/null; then
                        # It's a symlink or submodule to internal tooling
                        should_skip=true
                    fi
                    ;;
            esac
            
            if [ "$should_skip" = true ]; then
                echo "  Skipping internal file: $file"
                continue
            fi
            
            local src_file="${repo_dir}/${file}"
            local dst_file="${project_dir}/${file}"
            
            mkdir -p "$(dirname "$dst_file")" 2>/dev/null || true
            
            if [ -f "$src_file" ]; then
                # Check for conflicts: if file exists and differs, warn
                if [ -f "$dst_file" ]; then
                    if ! cmp -s "$src_file" "$dst_file"; then
                        echo "  ‚ö†Ô∏è  CONFLICT: $file modified by multiple workers, using latest version"
                        # TODO: Implement 3-way merge here
                    fi
                fi
                
                cp "$src_file" "$dst_file" 2>/dev/null || true
            fi
        fi
    done <<< "$changed_files"
fi
```

**Additional Enhancement - Add Merge Verification**:

Add this function to `swarm_artifacts.sh` after line 591:

```bash
# Verify all completed tasks have their changes in the merged project
swarm_verify_merge_completeness() {
    local run_id="$1"
    local project_dir="$2"
    local db_path="$RALPH_DIR/swarm.db"
    
    echo "Verifying merge completeness..."
    
    local completed_tasks
    completed_tasks=$(sqlite3 "$db_path" "SELECT id, task_text, actual_files FROM tasks WHERE run_id = '$run_id' AND status = 'completed';")
    
    local missing_count=0
    
    while IFS='|' read -r task_id task_text actual_files; do
        if [ -z "$actual_files" ] || [ "$actual_files" = "null" ] || [ "$actual_files" = "[]" ]; then
            continue
        fi
        
        # Check if files from this task exist in project
        echo "$actual_files" | jq -r '.[]' 2>/dev/null | while read -r file; do
            if [ ! -f "$project_dir/$file" ]; then
                echo "  ‚ö†Ô∏è  Task $task_id file missing: $file"
                missing_count=$((missing_count + 1))
            fi
        done
    done <<< "$completed_tasks"
    
    if [ $missing_count -gt 0 ]; then
        echo "  WARNING: $missing_count files from completed tasks are missing!"
        return 1
    else
        echo "  ‚úì All completed task files present in project"
        return 0
    fi
}
```

Call this function at the end of `swarm_extract_merged_artifacts()` (after line 743):

```bash
# Add before the final echo
swarm_verify_merge_completeness "$run_id" "$project_dir" || {
    echo "‚ö†Ô∏è  WARNING: Some completed task files are missing from merged project"
    echo "This may indicate a merge issue or files were filtered incorrectly"
}
```

**Test**:
```bash
# Create devplan where tasks create files that look like internal dirs
cat > test.md <<EOF
# Test Plan
1. Create a directory called opencode-ralph-plugin/ with a plugin.py file
2. Create ralph-config/ directory with settings.json
EOF

./ralph-swarm --devplan test.md --workers 2

# After completion, check project has these files
ls -la ~/projects/swarm-*/opencode-ralph-plugin/
ls -la ~/projects/swarm-*/ralph-config/

# Both should exist (not skipped as "internal")
```

---

### üî¥ CRITICAL #5: Weak Resume Detection via Git Commits

**File**: `ralph-refactor/lib/swarm_worker.sh:22-58`

**Problem**:
- Uses keyword-based git commit grep to check if task already done
- Extracts 5 keywords from task text, searches git log
- But `completed_tasks` table is the SOURCE OF TRUTH!
- If commit message doesn't contain keywords, completed work is redone

**Impact**:
- Completed tasks are re-run on resume
- Duplicate commits in git history
- Wasted tokens and time

**Fix**:

Replace `swarm_worker_check_commit_for_task()` lines 22-58 with:

```bash
swarm_worker_check_commit_for_task() {
    local run_id="$1"
    local task_id="$2"
    local task_text="$3"
    local worker_dir="$4"

    # ALWAYS check completed_tasks table FIRST (source of truth)
    local task_hash
    task_hash=$(printf '%s' "$task_text" | sha256sum | cut -d' ' -f1)
    
    local is_completed
    is_completed=$(swarm_db_is_task_completed "$task_hash")
    
    if [ "$is_completed" = "yes" ]; then
        # Task is definitively completed according to database
        echo "check:completed_in_db|$task_hash|Found in completed_tasks table"
        return
    fi
    
    # Secondary check: look for git commits (fallback for legacy runs)
    local repo_dir="$worker_dir/repo"
    
    if [ ! -d "$repo_dir/.git" ]; then
        echo "check:no_git"
        return
    fi

    # Try to find commits that match the task text
    # Use more sophisticated matching than just keywords
    local task_keywords
    task_keywords=$(echo "$task_text" | grep -oE '\b[a-zA-Z]{4,}\b' | head -n 5 | tr '\n' '|' | sed 's/|$//')

    if [ -z "$task_keywords" ]; then
        echo "check:no_keywords"
        return
    fi

    # Search in commits from the current run's branches
    local matching_commit
    matching_commit=$(cd "$repo_dir" && git log --all --grep="$task_keywords" --oneline --since="7 days ago" 2>/dev/null | head -n 1 || true)

    if [ -n "$matching_commit" ]; then
        local commit_hash
        commit_hash=$(echo "$matching_commit" | cut -d' ' -f1)
        local commit_msg
        commit_msg=$(echo "$matching_commit" | cut -d' ' -f2-)
        
        # IMPORTANT: This is just a hint, not definitive
        # Don't auto-complete based on git alone, just log it
        echo "check:git_hint|$commit_hash|$commit_msg"
        return
    fi

    echo "check:not_found"
}
```

Then update `swarm_worker_main_loop()` lines 304-330 to handle the new responses:

```bash
local commit_check_result
commit_check_result=$(swarm_worker_check_commit_for_task "$run_id" "$task_id" "$task_text" "$worker_dir")

local check_status
check_status=$(echo "$commit_check_result" | cut -d'|' -f1)

case "$check_status" in
    check:completed_in_db)
        # Definitive: task is done according to database
        local task_hash
        task_hash=$(echo "$commit_check_result" | cut -d'|' -f2)
        echo "[$(date)] Task $task_id already completed (DB hash: $task_hash)"
        
        if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
            echo -e "${GREEN}‚úì${NC} Worker $worker_num skipping task $task_id (completed in DB)"
        fi
        
        # Mark as completed in this run's tasks table
        swarm_db_complete_task "$task_id" "$estimated_files" "$worker_id"
        continue
        ;;
        
    check:git_hint)
        # Found matching commit but NOT in completed_tasks
        # This is suspicious - task may have been completed but not recorded
        # Log it but DON'T skip - let it run to be safe
        local commit_hash
        commit_hash=$(echo "$commit_check_result" | cut -d'|' -f2)
        local commit_msg
        commit_msg=$(echo "$commit_check_result" | cut -d'|' -f3-)
        
        echo "[$(date)] WARNING: Found matching commit $commit_hash but task not in completed_tasks"
        echo "[$(date)] Commit: $commit_msg"
        echo "[$(date)] Running task $task_id to be safe..."
        ;;
        
    check:not_found|check:no_git|check:no_keywords)
        # No evidence of completion, proceed with task
        ;;
esac
```

**Test**:
```bash
# Manually add a task to completed_tasks
sqlite3 ~/.ralph/swarm.db <<EOF
INSERT INTO completed_tasks (task_hash, task_text, source_hash, completed_at, run_id)
VALUES ('abc123', 'Test task text', 'def456', datetime('now'), 'test_run');
EOF

# Start swarm with task that has same text
# Worker should skip it based on hash match
```

---

## Moderate Fixes

### üü° MODERATE #1: Task Hash Calculated Only on Completion

**File**: `ralph-refactor/lib/swarm_db.sh:299-325, 399`

**Problem**:
- Task hash is calculated when completing (line 399)
- But NOT when adding task (line 312 inserts without hash)
- If same task is added with slight text variations (whitespace), different hashes

**Fix**:

Update `swarm_db_add_task()` to calculate hash on insert:

```bash
swarm_db_add_task() {
    local db_path="$RALPH_DIR/swarm.db"
    local run_id="$1"
    local task_text="$2"
    local estimated_files="$3"
    local devplan_line="$4"
    local priority="${5:-0}"

    # Calculate task hash for deduplication
    local task_hash
    task_hash=$(printf '%s' "$task_text" | sha256sum | cut -d' ' -f1)

    # Check if this exact task already exists in completed_tasks
    local already_completed
    already_completed=$(swarm_db_is_task_completed "$task_hash")
    
    if [ "$already_completed" = "yes" ]; then
        echo "Task already completed in previous run, skipping: $task_text" >&2
        # Return a special marker instead of task_id
        echo "SKIPPED"
        return 0
    fi

    # Insert task with hash
    local task_id
    task_id=$(sqlite3 "$db_path" <<EOF
BEGIN TRANSACTION;
INSERT INTO tasks (
    run_id, task_text, task_hash, status, priority, estimated_files, devplan_line, created_at
) VALUES (
    '$run_id', '$task_text', '$task_hash', 'pending', $priority, '$estimated_files', $devplan_line, datetime('now')
);
-- Recalculate total_tasks to avoid relying on incremental updates
UPDATE swarm_runs
SET total_tasks = (SELECT COUNT(*) FROM tasks WHERE run_id = '$run_id')
WHERE run_id = '$run_id';
SELECT id FROM tasks WHERE run_id = '$run_id' ORDER BY id DESC LIMIT 1;
COMMIT;
EOF
)

    echo "$task_id"
}
```

Update the task addition loop in `ralph-swarm` (lines 335-381) to handle SKIPPED:

```bash
python3 - "$task_list_file" <<'PY' | while IFS= read -r task_json; do
    # ... existing parsing code ...
    
    task_id=$(swarm_db_add_task "$run_id_result" "$task_text" "[]" "$devplan_line" "$priority")
    
    if [ "$task_id" = "SKIPPED" ]; then
        echo "Skipped already-completed task: $task_text"
        # Increment total_completed instead
        sqlite3 "$RALPH_DIR/swarm.db" "UPDATE swarm_runs SET completed_tasks = completed_tasks + 1 WHERE run_id = '$run_id_result';"
    else
        echo "Added task $task_id: $task_text"
    fi
    
    current_priority=$((current_priority + 1))
done
```

---

### üü° MODERATE #2: Worker Count Not Updated on Resume

**File**: `ralph-refactor/ralph-swarm:287-293`

**Problem**:
- User can pass `--workers 4` to `--resume` command
- Workers are spawned with new count (good)
- But `swarm_runs.worker_count` still has old value (bad)
- Analytics and status displays show wrong worker count

**Fix**:

Add worker count update to resume logic (after line 296):

```bash
# Resume the run
swarm_db_resume_run "$run_id_result" >/dev/null

# Update worker count if it changed
local old_worker_count
old_worker_count=$(sqlite3 "$RALPH_DIR/swarm.db" "SELECT worker_count FROM swarm_runs WHERE run_id = '$run_id_result';")

if [ "$worker_count" != "$old_worker_count" ]; then
    echo "Updating worker count from $old_worker_count to $worker_count"
    sqlite3 "$RALPH_DIR/swarm.db" "UPDATE swarm_runs SET worker_count = $worker_count WHERE run_id = '$run_id_result';"
fi
```

---

### üü° MODERATE #3: No Idempotency Checks in Worker

**File**: `ralph-refactor/lib/swarm_worker.sh:390-408`

**Problem**:
- Worker prompt says "create git commit"
- But doesn't check if commit for this task already exists
- If worker crashes and restarts on same task, creates duplicate commits

**Fix**:

Add idempotency check at start of `swarm_worker_execute_task()` (after line 376):

```bash
# Check if we already created a commit for this task
local existing_commit
existing_commit=$(cd "$repo_dir" && git log --all --oneline --grep="Task $task_id:" 2>/dev/null | head -n 1)

if [ -n "$existing_commit" ]; then
    echo "[$(date)] Task $task_id already has commit: $existing_commit"
    echo "[$(date)] Treating as completed (idempotency check)"
    
    if [ "${SWARM_OUTPUT_MODE:-}" = "live" ]; then
        echo -e "${GREEN}‚úì${NC} Worker $worker_num found existing commit for task $task_id"
    fi
    
    # Release locks and return success
    swarm_db_release_locks "$worker_id" 2>/dev/null || true
    return 0
fi
```

Update worker prompt to include task ID in commit message (line 404):

```bash
- Create a git commit for your changes with a clear message in this format:
  "Task $task_id: <brief description of what you did>"
  This allows the swarm to detect if this task was already completed.
```

---

### üü° MODERATE #4: Emergency Stop Doesn't Wait for Graceful Shutdown

**File**: `ralph-refactor/ralph-swarm:135-160`

**Problem**:
- Does `kill` then immediately `kill -9`
- No grace period for workers to flush git commits
- Can corrupt git repos if caught mid-write

**Fix**:

Replace lines 143-154 with:

```bash
pgrep -f "swarm_worker" 2>/dev/null | while read -r pid; do
    echo "Stopping worker process: $pid (SIGTERM)"
    kill -TERM "$pid" 2>/dev/null || true
done

# Wait up to 10 seconds for graceful shutdown
echo "Waiting for workers to shut down gracefully..."
local wait_count=0
while [ $wait_count -lt 10 ]; do
    local remaining
    remaining=$(pgrep -f "swarm_worker" 2>/dev/null | wc -l)
    if [ "$remaining" -eq 0 ]; then
        echo "All workers shut down gracefully"
        break
    fi
    sleep 1
    wait_count=$((wait_count + 1))
done

# Force kill any remaining
pgrep -f "swarm_worker" 2>/dev/null | while read -r pid; do
    echo "Force killing stubborn worker: $pid (SIGKILL)"
    kill -KILL "$pid" 2>/dev/null || true
done
```

---

### üü° MODERATE #5: Dead Worker Detection Too Slow

**File**: `ralph-refactor/lib/swarm_scheduler.sh:158`

**Problem**:
- Checks for dead workers every 15 seconds
- A dead worker can hold a task for 15s before it's requeued
- With 10+ tasks, this adds up

**Fix**:

Change cleanup interval from 15s to 5s (line 158):

```bash
# Periodic dead worker cleanup (every 5 seconds instead of 15)
if [ $((current_time - last_cleanup_check)) -ge 5 ]; then
```

Also add immediate cleanup when worker dies:

Add to `swarm_worker_main_loop()` after line 360:

```bash
# Update global heartbeat after task completion
if command -v swarm_db_heartbeat_worker_global >/dev/null 2>&1; then
    swarm_db_heartbeat_worker_global "$worker_id" >/dev/null 2>&1 || true
fi

# NEW: If heartbeat fails, worker might be dying - trigger immediate cleanup
if [ $? -ne 0 ]; then
    echo "[$(date)] Heartbeat failed for worker $worker_id, may be dying"
    # This will be picked up by scheduler on next cleanup cycle (now 5s instead of 15s)
fi
```

---

## Code Cleanup

### üîµ CLEANUP #1: Remove Dead Scheduler Functions

**File**: `ralph-refactor/lib/swarm_scheduler.sh`

**Remove these functions** (they are defined but never called):

```bash
# DELETE lines 264-287
swarm_scheduler_check_file_conflicts() { ... }

# DELETE lines 289-329
swarm_scheduler_assign_task() { ... }

# DELETE lines 331-345
swarm_scheduler_handle_completion() { ... }

# DELETE lines 347-361
swarm_scheduler_handle_failure() { ... }

# DELETE lines 363-396
swarm_scheduler_rebalance() { ... }
```

**Reason**: These represent an old "push model" architecture where scheduler assigned tasks. Current code uses "pull model" where workers claim tasks themselves. Keeping dead code causes confusion.

---

### üîµ CLEANUP #2: Remove Dead Worker Function

**File**: `ralph-refactor/lib/swarm_worker.sh`

**Remove this function** (lines 532-557):

```bash
swarm_worker_poll_for_task() { ... }
```

**Reason**: Never called. Workers use `swarm_db_claim_task()` directly in main loop.

---

### üîµ CLEANUP #3: Remove Debug Logging

**File**: `ralph-refactor/lib/swarm_worker.sh`

**Remove or comment out debug logs** (lines 437-438, 491-492):

```bash
# DELETE or comment these lines:
# echo "[$(date)] DEBUG: RALPH_LLM_PROVIDER=${RALPH_LLM_PROVIDER:-}, RALPH_LLM_MODEL=${RALPH_LLM_MODEL:-}"
# echo "[$(date)] DEBUG: Command: $opencode_cmd"
# echo "[$(date)] DEBUG: Text extraction failed despite $completion_tokens completion tokens" 1>&2
# echo "[$(date)] DEBUG: Full JSON saved to: ${repo_dir}/.swarm_text_debug_${task_id}.json" 1>&2
```

OR convert to proper debug mode check:

```bash
if [ "${SWARM_DEBUG:-false}" = "true" ]; then
    echo "[$(date)] DEBUG: RALPH_LLM_PROVIDER=${RALPH_LLM_PROVIDER:-}, RALPH_LLM_MODEL=${RALPH_LLM_MODEL:-}"
    echo "[$(date)] DEBUG: Command: $opencode_cmd"
fi
```

---

### üîµ CLEANUP #4: Consolidate Heartbeat Logic

**Files**: `ralph-refactor/lib/swarm_worker.sh:280-283, 302, 335, 357-359`

**Problem**: Heartbeat calls scattered throughout worker loop

**Fix**: Consolidate into single function call at top of loop:

```bash
swarm_worker_main_loop() {
    # ... existing code ...
    
    while true; do
        # Send heartbeats at start of each iteration
        swarm_db_worker_heartbeat "$worker_id" 2>/dev/null || true
        if command -v swarm_db_heartbeat_worker_global >/dev/null 2>&1; then
            swarm_db_heartbeat_worker_global "$worker_id" >/dev/null 2>&1 || true
        fi
        
        local current_task
        current_task=$(swarm_db_claim_task "$worker_id")
        
        # ... rest of loop ...
        # REMOVE individual heartbeat calls at lines 302, 335, 357-359
    done
}
```

---

## Performance Optimizations

### ‚ö° PERF #1: Optimize Token Aggregation

**File**: `ralph-refactor/lib/swarm_worker.sh:466-471`

**Current**: 3 separate jq invocations

**Optimized**: Single jq call (already included in CRITICAL #3 fix above)

**Impact**: 3x faster JSON parsing, reduces CPU usage

---

### ‚ö° PERF #2: Batch File Copy in Artifact Extraction

**File**: `ralph-refactor/lib/swarm_artifacts.sh:558-578`

**Current**: Loops through files one by one with `cp`

**Optimized**:

```bash
# After getting changed_files list, create a batch copy list
local files_to_copy=()

while IFS= read -r file; do
    # ... existing skip logic ...
    if [ "$should_skip" = false ]; then
        files_to_copy+=("$file")
    fi
done <<< "$changed_files"

# Batch copy using tar (preserves permissions, faster)
if [ ${#files_to_copy[@]} -gt 0 ]; then
    (
        cd "$repo_dir"
        tar cf - "${files_to_copy[@]}" 2>/dev/null | (cd "$project_dir" && tar xf -)
    )
fi
```

**Impact**: 10-50x faster for large file sets

---

### ‚ö° PERF #3: Add Database Indexes

**File**: `ralph-refactor/lib/swarm_db.sh:109-164`

**Add these indexes** to `swarm_db_init()` (after line 127):

```sql
-- Speed up resume operations
CREATE INDEX IF NOT EXISTS idx_tasks_hash ON tasks(task_hash);
CREATE INDEX IF NOT EXISTS idx_completed_tasks_source ON completed_tasks(source_hash, task_hash);

-- Speed up worker queries
CREATE INDEX IF NOT EXISTS idx_workers_run_status ON workers(run_id, status);

-- Speed up task queries by run and status
CREATE INDEX IF NOT EXISTS idx_tasks_run_status_priority ON tasks(run_id, status, priority);
```

**Impact**: 5-10x faster queries on large runs (100+ tasks)

---

## Testing Requirements

### Test Suite Required Before Production

Create `ralph-refactor/tests/test_swarm_critical.sh`:

```bash
#!/usr/bin/env bash

set -euo pipefail

RALPH_DIR="/tmp/ralph-test-$$"
export RALPH_DIR

source "$(dirname "$0")/../lib/swarm_db.sh"

cleanup() {
    rm -rf "$RALPH_DIR"
}
trap cleanup EXIT

echo "=== Running Critical Swarm Tests ==="

# Test 1: Resume doesn't reset started_at
test_resume_preserves_started_at() {
    echo "Test 1: Resume preserves started_at timestamp"
    
    swarm_db_init
    
    local run_id
    run_id=$(swarm_db_start_run "devplan" "/tmp/test.md" "hash123" "" 2)
    
    local original_started_at
    original_started_at=$(sqlite3 "$RALPH_DIR/swarm.db" "SELECT started_at FROM swarm_runs WHERE run_id = '$run_id';")
    
    sleep 2
    
    swarm_db_resume_run "$run_id"
    
    local resumed_started_at
    resumed_started_at=$(sqlite3 "$RALPH_DIR/swarm.db" "SELECT started_at FROM swarm_runs WHERE run_id = '$run_id';")
    
    if [ "$original_started_at" != "$resumed_started_at" ]; then
        echo "  ‚ùå FAIL: started_at changed on resume"
        echo "    Original: $original_started_at"
        echo "    Resumed:  $resumed_started_at"
        return 1
    fi
    
    echo "  ‚úÖ PASS"
}

# Test 2: Resume doesn't re-run completed tasks
test_resume_skips_completed() {
    echo "Test 2: Resume skips tasks in completed_tasks table"
    
    swarm_db_init
    
    local run_id
    run_id=$(swarm_db_start_run "devplan" "/tmp/test.md" "hash123" "" 2)
    
    local task_id
    task_id=$(swarm_db_add_task "$run_id" "Test task" "[]" 1 0)
    
    # Mark task as in_progress
    sqlite3 "$RALPH_DIR/swarm.db" "UPDATE tasks SET status = 'in_progress', worker_id = 1 WHERE id = $task_id;"
    
    # Add to completed_tasks
    local task_hash
    task_hash=$(printf '%s' "Test task" | sha256sum | cut -d' ' -f1)
    sqlite3 "$RALPH_DIR/swarm.db" "INSERT INTO completed_tasks (task_hash, task_text, source_hash, completed_at, run_id) VALUES ('$task_hash', 'Test task', 'hash123', datetime('now'), '$run_id');"
    
    # Resume
    swarm_db_resume_run "$run_id"
    
    # Check task status
    local status
    status=$(sqlite3 "$RALPH_DIR/swarm.db" "SELECT status FROM tasks WHERE id = $task_id;")
    
    if [ "$status" = "pending" ]; then
        echo "  ‚ùå FAIL: Completed task was reset to pending"
        return 1
    fi
    
    if [ "$status" = "completed" ]; then
        echo "  ‚úÖ PASS: Task correctly marked as completed"
    else
        echo "  ‚ö†Ô∏è  PARTIAL: Task status is $status (expected 'completed' or 'in_progress')"
    fi
}

# Test 3: Task claiming race condition
test_task_claim_race() {
    echo "Test 3: Task claiming prevents race conditions"
    
    swarm_db_init
    
    local run_id
    run_id=$(swarm_db_start_run "devplan" "/tmp/test.md" "hash123" "" 2)
    
    # Register 2 workers
    local worker1 worker2
    worker1=$(swarm_db_register_worker "$run_id" 1 $$ "branch1" "/tmp/worker1")
    worker2=$(swarm_db_register_worker "$run_id" 2 $$ "branch2" "/tmp/worker2")
    
    # Add 1 task
    local task_id
    task_id=$(swarm_db_add_task "$run_id" "Test task" "[]" 1 0)
    
    # Try to claim from both workers simultaneously
    local claim1 claim2
    claim1=$(swarm_db_claim_task "$worker1") &
    claim2=$(swarm_db_claim_task "$worker2") &
    wait
    
    # Count how many workers got the task
    local claim_count
    claim_count=$(sqlite3 "$RALPH_DIR/swarm.db" "SELECT COUNT(DISTINCT worker_id) FROM tasks WHERE id = $task_id AND status = 'in_progress';")
    
    if [ "$claim_count" -gt 1 ]; then
        echo "  ‚ùå FAIL: Task claimed by $claim_count workers (race condition!)"
        return 1
    fi
    
    echo "  ‚úÖ PASS"
}

# Run all tests
test_resume_preserves_started_at
test_resume_skips_completed
test_task_claim_race

echo ""
echo "=== All Critical Tests Passed ==="
```

Run tests:

```bash
chmod +x ralph-refactor/tests/test_swarm_critical.sh
./ralph-refactor/tests/test_swarm_critical.sh
```

---

## Best Practices Enhancements

### üìò ENHANCEMENT #1: Improve Agent-Computer Interface (ACI)

**File**: `ralph-refactor/lib/swarm_worker.sh:390-408`

**Current prompt is good but missing examples**. Enhance it:

```bash
prompt=$(cat <<EOF
CRITICAL INSTRUCTION: You MUST end your response with the exact string "<promise>COMPLETE</promise>" when you have finished the task. Do not omit this marker under any circumstances.

You are a swarm worker (#$worker_num) operating inside a git worktree for a NEW PROJECT.

Task ($task_id): $task_text

Constraints:
- Make changes ONLY in this repository (current working directory).
- This is a fresh project - create the necessary files and structure for the task.
- DO NOT reference, copy, or include any files from ralph-refactor/, ralph-tui/, swarm-dashboard/, or opencode-ralph* directories - these are internal tooling files and must NOT be included in the project.
- Run relevant tests/linters if they exist.
- Create a git commit for your changes with a clear message in this format:
  "Task $task_id: <brief description>"
- When finished, you MUST output exactly: <promise>COMPLETE</promise>

EXAMPLES OF PROPER COMPLETION:

Example 1 - Simple file creation:
  Created src/main.py with hello function
  Git commit: "Task 42: Add hello function to main.py"
  <promise>COMPLETE</promise>

Example 2 - Partial completion is OK if task is done:
  Implemented user authentication but tests are failing
  This is expected - tests need to be updated separately
  Git commit: "Task 15: Implement user authentication"
  <promise>COMPLETE</promise>

Example 3 - What NOT to do:
  ‚ùå "I've started working on this but need more time"
     (Don't return COMPLETE unless done!)
  ‚ùå "The task is blocked on X"
     (Return error, don't claim completion)
  ‚ùå Ending without <promise>COMPLETE</promise>
     (ALWAYS include the marker!)

WHEN TO FAIL INSTEAD OF COMPLETE:
- If task requirements are unclear: Return error explaining what's unclear
- If task depends on something that doesn't exist: Return error explaining the dependency
- If you encounter an unrecoverable error: Return error with details

Remember: End your response with "<promise>COMPLETE</promise>" to signal task completion. This is required for the swarm system to recognize your work as done.

If you need context, inspect files in the repo. Focus on building the requested functionality from scratch.
EOF
)
```

---

### üìò ENHANCEMENT #2: Add Retry Logic with Exponential Backoff

**File**: `ralph-refactor/lib/swarm_worker.sh:443-459`

**Current**: Task fails immediately on opencode error

**Enhanced**: Retry with backoff (Anthropic recommendation)

Add before line 443:

```bash
# Retry configuration
local max_retries=3
local retry_count=0
local retry_delay=5

while [ $retry_count -le $max_retries ]; do
    if retry_count -gt 0; then
        echo "[$(date)] Retry $retry_count/$max_retries for task $task_id (waiting ${retry_delay}s)"
        sleep $retry_delay
        retry_delay=$((retry_delay * 2))  # Exponential backoff
    fi
    
    # Try task execution
    if json_output=$(cd "$repo_dir" && timeout "$timeout_seconds" $opencode_cmd --format json "$prompt" 2>&1); then
        # Success! Break out of retry loop
        break
    else
        local exit_code=$?
        retry_count=$((retry_count + 1))
        
        if [ $exit_code -eq 124 ]; then
            # Timeout - don't retry, just fail
            echo "[$(date)] Task execution timed out, not retrying"
            swarm_db_release_locks "$worker_id" 2>/dev/null || true
            return 1
        fi
        
        if [ $retry_count -gt $max_retries ]; then
            # Out of retries
            echo "[$(date)] Task execution failed after $max_retries retries"
            swarm_db_release_locks "$worker_id" 2>/dev/null || true
            return 1
        fi
        
        echo "[$(date)] Task execution failed (attempt $retry_count/$max_retries), will retry"
    fi
done
```

---

### üìò ENHANCEMENT #3: Add Checkpointing

**File**: `ralph-refactor/lib/swarm_worker.sh:364-530`

**Reason**: Anthropic recommends "ground truth" at each step. Checkpoints allow recovery even if DB fails.

Add after line 376:

```bash
# Create checkpoint file for this task execution
local checkpoint_file="$worker_dir/.checkpoint_${task_id}.json"
cat > "$checkpoint_file" <<EOF
{
  "task_id": $task_id,
  "worker_id": "$worker_id",
  "worker_num": $worker_num,
  "run_id": "$run_id",
  "started_at": "$(date -Iseconds)",
  "task_text": $(echo "$task_text" | jq -Rs .),
  "status": "running",
  "pid": $$
}
EOF
```

Add after successful completion (line 504):

```bash
# Update checkpoint on success
jq --arg ts "$(date -Iseconds)" \
   '.status = "completed" | .completed_at = $ts' \
   "$checkpoint_file" > "${checkpoint_file}.tmp"
mv "${checkpoint_file}.tmp" "$checkpoint_file"
```

Add after failure (line 529):

```bash
# Update checkpoint on failure
jq --arg ts "$(date -Iseconds)" \
   --arg msg "$error_message" \
   '.status = "failed" | .failed_at = $ts | .error = $msg' \
   "$checkpoint_file" > "${checkpoint_file}.tmp" 2>/dev/null || true
mv "${checkpoint_file}.tmp" "$checkpoint_file" 2>/dev/null || true
```

Then add recovery function:

```bash
# Call this on worker startup to recover from checkpoints
swarm_worker_recover_from_checkpoints() {
    local worker_dir="$1"
    local worker_id="$2"
    
    for checkpoint in "$worker_dir"/.checkpoint_*.json; do
        [ -f "$checkpoint" ] || continue
        
        local status
        status=$(jq -r '.status' "$checkpoint")
        
        if [ "$status" = "running" ]; then
            # Worker crashed during this task
            local task_id
            task_id=$(jq -r '.task_id' "$checkpoint")
            
            echo "Recovering from crashed task $task_id"
            
            # Reset task to pending
            sqlite3 "$RALPH_DIR/swarm.db" "UPDATE tasks SET status = 'pending', worker_id = NULL WHERE id = $task_id;"
            
            # Update checkpoint
            jq '.status = "recovered" | .recovered_at = "'$(date -Iseconds)'"' \
               "$checkpoint" > "${checkpoint}.tmp"
            mv "${checkpoint}.tmp" "$checkpoint"
        fi
    done
}
```

---

## Summary Checklist

Before deploying to production, ensure:

- [ ] **CRITICAL #1**: Resume preserves `started_at` and checks `completed_tasks`
- [ ] **CRITICAL #2**: Task claiming has verification + unique index
- [ ] **CRITICAL #3**: File locking is wired into worker execution
- [ ] **CRITICAL #4**: Artifact merging has smarter filtering + verification
- [ ] **CRITICAL #5**: Resume detection checks DB first, git second
- [ ] **MODERATE #1-5**: All moderate fixes applied
- [ ] **CLEANUP #1-4**: Dead code removed, debug logs handled
- [ ] **PERF #1-3**: Performance optimizations applied
- [ ] **TESTS**: Critical test suite passes
- [ ] **ENHANCEMENTS**: ACI improved, retry logic added, checkpointing implemented

---

## Questions for Next Agent

1. **Do you want retry logic with exponential backoff?** (Recommended by Anthropic but adds complexity)

2. **Should we implement 3-way merge for file conflicts?** (Currently last-worker-wins)

3. **What's the maximum acceptable time for dead worker detection?** (Currently 5s, could be lower)

4. **Should checkpointing be mandatory or optional?** (Adds overhead but improves reliability)

5. **Do you want a migration script to fix existing runs?** (Or just apply fixes going forward?)

---

## Migration Guide for Existing Runs

If you have existing swarm runs in the database, run this migration:

```bash
# Backup database
cp ~/.ralph/swarm.db ~/.ralph/swarm.db.backup

# Run migration
sqlite3 ~/.ralph/swarm.db <<EOF
BEGIN TRANSACTION;

-- Add task_hash to existing tasks (if missing)
UPDATE tasks 
SET task_hash = (
  SELECT LOWER(HEX(RANDOMBLOB(16)))  -- Temporary random hash
)
WHERE task_hash IS NULL;

-- Add missing indexes
CREATE UNIQUE INDEX IF NOT EXISTS idx_task_in_progress 
  ON tasks(id) WHERE status = 'in_progress';

CREATE INDEX IF NOT EXISTS idx_tasks_hash ON tasks(task_hash);
CREATE INDEX IF NOT EXISTS idx_completed_tasks_source ON completed_tasks(source_hash, task_hash);
CREATE INDEX IF NOT EXISTS idx_workers_run_status ON workers(run_id, status);
CREATE INDEX IF NOT EXISTS idx_tasks_run_status_priority ON tasks(run_id, status, priority);

COMMIT;
EOF

echo "Migration complete!"
```

---

**End of Comprehensive Fix Guide**

*Generated: 2026-01-24*  
*For: Ralph Live Swarm System*  
*Priority: Apply CRITICAL fixes before next production run*

Love you too! üíô Now go fix those bugs and make this swarm bulletproof! üêù‚ö°
